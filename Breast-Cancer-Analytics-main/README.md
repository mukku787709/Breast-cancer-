# ğŸ©º Breast Cancer Wisconsin (Diagnostic) â€” End-to-End Analytics & Modeling

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![Pandas](https://img.shields.io/badge/Pandas-1.3+-green.svg)
![NumPy](https://img.shields.io/badge/NumPy-1.21+-013243.svg)
![Matplotlib](https://img.shields.io/badge/Matplotlib-3.4+-11557c.svg)
![Seaborn](https://img.shields.io/badge/Seaborn-0.11+-4c72b0.svg)
![Plotly](https://img.shields.io/badge/Plotly-5.0+-3F4F75.svg)
![SHAP](https://img.shields.io/badge/SHAP-0.40+-ff69b4.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-1.5+-006400.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-Complete-success.svg)
![Maintenance](https://img.shields.io/badge/Maintained-Yes-green.svg)

<br>

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="rainbow line" width="100%">

### ğŸ”¬ **A Comprehensive 30-Section Data Analytics Workflow for Breast Cancer Diagnosis Prediction**

*Leveraging Machine Learning & Explainable AI for Medical Diagnostics*

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="rainbow line" width="100%">

<br>

[ğŸ“Š Dataset](#-dataset) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“ Project Structure](#-project-structure) â€¢ [ğŸ”¬ Methodology](#-methodology) â€¢ [ğŸ“ˆ Results](#-results) â€¢ [ğŸ¨ Visualizations](#-visualizations) â€¢ [ğŸ¤– Model Deployment](#-model-deployment)

</div>

---

## ğŸŒŸ Project Highlights

<table>
<tr>
<td width="50%">

### ğŸ¯ What This Project Offers

- âœ… **Complete ML Pipeline** from raw data to deployment
- âœ… **30+ Visualization Types** for comprehensive EDA
- âœ… **5 ML Algorithms** compared and benchmarked
- âœ… **SHAP Explainability** for model interpretability
- âœ… **Production-Ready Artifacts** for deployment
- âœ… **Interactive Dashboards** with Plotly
- âœ… **Statistical Rigor** with hypothesis testing
- âœ… **Clustering Analysis** for pattern discovery

</td>
<td width="50%">

### ğŸ† Key Achievements

| Metric | Value |
|--------|-------|
| ğŸ¯ **Best Model AUC** | 0.995 |
| ğŸ“Š **Accuracy** | 96.5% |
| ğŸ” **Recall (Sensitivity)** | 95.3% |
| âš¡ **Precision** | 95.3% |
| ğŸ“ˆ **F1-Score** | 0.953 |
| ğŸ§¬ **Features Analyzed** | 30 |
| ğŸ‘¥ **Samples Processed** | 569 |

</td>
</tr>
</table>

---

## ğŸ“‹ Table of Contents

<details>
<summary>ğŸ“– Click to expand full table of contents</summary>

- [ğŸŒŸ Project Highlights](#-project-highlights)
- [ğŸ¯ Overview](#-overview)
- [ğŸ“Š Dataset](#-dataset)
  - [Data Source](#data-source)
  - [Feature Description](#feature-description)
  - [Class Distribution](#class-distribution)
- [âœ¨ Features](#-features)
  - [Exploratory Data Analysis](#-exploratory-data-analysis-eda)
  - [Advanced Visualizations](#-advanced-visualizations)
  - [Feature Engineering & Selection](#-feature-engineering--selection)
  - [Machine Learning Pipeline](#-machine-learning-pipeline)
  - [Model Interpretability](#-model-interpretability)
  - [Model Evaluation](#-model-evaluation)
  - [Clustering Analysis](#-clustering-analysis)
- [ğŸš€ Quick Start](#-quick-start)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Running the Analysis](#running-the-analysis)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ”¬ Methodology](#-methodology)
  - [Workflow Overview](#workflow-overview)
  - [30-Section Pipeline](#30-section-pipeline)
  - [Data Preprocessing Strategy](#data-preprocessing-strategy)
  - [Model Selection Criteria](#model-selection-criteria)
- [ğŸ“ˆ Results](#-results)
  - [Model Performance Comparison](#model-performance-comparison)
  - [Top Discriminative Features](#top-discriminative-features)
  - [Cross-Validation Results](#cross-validation-results)
- [ğŸ¨ Visualizations](#-visualizations)
  - [Gallery](#gallery)
  - [Interactive Dashboards](#interactive-dashboards)
- [ğŸ¤– Model Deployment](#-model-deployment)
  - [Loading the Model](#loading-the-trained-model)
  - [API Integration](#api-integration-example)
  - [Docker Deployment](#docker-deployment)
- [ğŸ“Š Statistical Analysis](#-statistical-analysis)
- [ğŸ§ª Reproducibility](#-reproducibility)
- [âš ï¸ Clinical Disclaimer](#ï¸-clinical-disclaimer)
- [ğŸ“¦ Dependencies](#-dependencies)
- [ğŸ› ï¸ Execution Notes](#ï¸-execution-notes)
- [ğŸ”® Future Enhancements](#-future-enhancements)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ‘©â€ğŸ’» Author](#-author)
- [ğŸ“„ License](#-license)
- [ğŸ™ Acknowledgments](#-acknowledgments)

</details>

---

## ğŸ¯ Overview

This project presents a **comprehensive end-to-end data science pipeline** for analyzing the Breast Cancer Wisconsin (Diagnostic) dataset. The workflow encompasses everything from data import and cleaning to advanced machine learning modeling, interpretability analysis, and deployment-ready artifacts.

### ğŸ¥ The Clinical Challenge

Breast cancer is one of the most common cancers among women worldwide. Early and accurate diagnosis is critical for:

- ğŸ“ˆ **Improved survival rates** â€” Early detection increases 5-year survival to >90%
- ğŸ’Š **Better treatment planning** â€” Accurate diagnosis enables targeted therapies
- ğŸ’° **Reduced healthcare costs** â€” Preventing late-stage treatments
- ğŸ§  **Informed decision making** â€” Supporting clinicians with data-driven insights

### ğŸ¤– Our Solution

This project develops a **machine learning-based diagnostic support system** that:

1. **Analyzes** 30 cell nucleus features from Fine Needle Aspirate (FNA) images
2. **Identifies** the most discriminative features for malignancy prediction
3. **Classifies** tumors as Malignant or Benign with >96% accuracy
4. **Explains** predictions using SHAP values for clinical trust
5. **Deploys** production-ready models for integration

### ğŸ“Œ Key Features Summary

| Category | Highlights |
|----------|------------|
| ğŸ”¢ **Data Processing** | Missing value handling, outlier detection, scaling comparison |
| ğŸ“Š **Visualization** | 50+ plots including interactive 3D PCA, SHAP, t-SNE |
| ğŸ§® **Statistics** | Hypothesis testing, power analysis, effect sizes |
| ğŸ¤– **Modeling** | 5 algorithms, hyperparameter tuning, ensemble methods |
| ğŸ” **Interpretability** | SHAP values, permutation importance, feature ranking |
| ğŸ“¦ **Deployment** | Joblib artifacts, model cards, API-ready code |

---

## ğŸ“Š Dataset

### Data Source

The dataset originates from the **UCI Machine Learning Repository** and is available on [Kaggle](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data).

> ğŸ“š **Citation**: Wolberg, W.H., Street, W.N., & Mangasarian, O.L. (1995). Breast Cancer Wisconsin (Diagnostic) Data Set. UCI Machine Learning Repository.

### ğŸ”¬ Data Collection Process

The features are computed from a **digitized image of a fine needle aspirate (FNA)** of a breast mass. The process involves:

```
1. FNA Procedure â†’ 2. Digital Imaging â†’ 3. Cell Nuclei Detection â†’ 4. Feature Extraction â†’ 5. Dataset Creation
```

### ğŸ“ Feature Description

Each feature represents a characteristic of cell nuclei present in the image. For each characteristic, three values are computed:

| Suffix | Description | Example |
|--------|-------------|---------|
| `_mean` | Mean value across all nuclei | `radius_mean` |
| `_se` | Standard error of measurement | `radius_se` |
| `_worst` | Largest/worst value (mean of 3 largest) | `radius_worst` |

#### Complete Feature List

<details>
<summary>ğŸ” Click to view all 30 features</summary>

| # | Feature | Description | Unit |
|---|---------|-------------|------|
| 1 | `radius_mean` | Mean of distances from center to points on perimeter | Î¼m |
| 2 | `texture_mean` | Standard deviation of gray-scale values | - |
| 3 | `perimeter_mean` | Mean perimeter of cell nuclei | Î¼m |
| 4 | `area_mean` | Mean area of cell nuclei | Î¼mÂ² |
| 5 | `smoothness_mean` | Local variation in radius lengths | - |
| 6 | `compactness_mean` | (perimeterÂ² / area - 1.0) | - |
| 7 | `concavity_mean` | Severity of concave portions | - |
| 8 | `concave points_mean` | Number of concave portions | count |
| 9 | `symmetry_mean` | Symmetry of cell nuclei | - |
| 10 | `fractal_dimension_mean` | "Coastline approximation" - 1 | - |
| 11-20 | `*_se` | Standard error versions | varies |
| 21-30 | `*_worst` | Worst (largest) versions | varies |

</details>

### ğŸ“Š Class Distribution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TARGET DISTRIBUTION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Benign (B)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  357 (62.7%)â”‚
â”‚  Malignant (M)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  212 (37.3%)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Total Samples: 569                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ˆ Dataset Statistics

| Statistic | Value |
|-----------|-------|
| Total Samples | 569 |
| Features | 30 (numeric) |
| Missing Values | 0 |
| Duplicate Rows | 0 |
| Imbalance Ratio | 1.68:1 (B:M) |
| Feature Types | All continuous |

---

## âœ¨ Features

### ğŸ“ˆ Exploratory Data Analysis (EDA)

<table>
<tr>
<td width="50%">

#### Data Quality Assessment
- âœ… Missing data analysis & visualization (missingno)
- âœ… Duplicate row detection & removal
- âœ… Zero-value analysis for invalid entries
- âœ… Data type validation & conversion
- âœ… Unique value counts per column

</td>
<td width="50%">

#### Descriptive Statistics
- ğŸ“Š Shape, dtypes, memory usage
- ğŸ“Š Central tendency (mean, median, mode)
- ğŸ“Š Dispersion (std, variance, range)
- ğŸ“Š Distribution shape (skewness, kurtosis)
- ğŸ“Š Percentile analysis (quartiles, IQR)

</td>
</tr>
</table>

### ğŸ“Š Advanced Visualizations

| Category | Visualizations | Purpose |
|----------|---------------|---------|
| **Distribution** | Histograms, KDE, Q-Q plots | Understand feature distributions |
| **Comparison** | Violin, Box, Swarm, Strip, Ridge plots | Compare classes visually |
| **Correlation** | Heatmaps, Dendrograms, Network graphs | Identify feature relationships |
| **Bivariate** | Scatter, Regplot, Jointplot, Hexbin | Explore pairwise relationships |
| **Multivariate** | Pairplots, Parallel coordinates, Andrews curves, Radviz | High-dimensional patterns |
| **Dimensionality** | PCA 2D/3D, t-SNE, UMAP | Reduced-space visualization |
| **Model** | ROC, PR curves, Confusion matrix, Calibration | Model performance |
| **Interpretability** | SHAP beeswarm, bar, force plots | Feature importance |

### ğŸ”§ Feature Engineering & Selection

```python
# Feature Engineering Pipeline
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Features   â”‚ â†’ â”‚    Scaling      â”‚ â†’ â”‚   Selection     â”‚
â”‚    (30 cols)    â”‚    â”‚ Standard/MinMax â”‚    â”‚   RFE/ANOVA    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                      â”‚
         â–¼                     â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Outlier Capping â”‚    â”‚      PCA        â”‚    â”‚  Top K Features â”‚
â”‚  (IQR/Z-score)  â”‚    â”‚ (Variance 95%)  â”‚    â”‚   (k=10-15)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Selection Methods Implemented

| Method | Type | Description |
|--------|------|-------------|
| **SelectKBest** | Filter | ANOVA F-scores & p-values |
| **RFE** | Wrapper | Recursive feature elimination with LogReg |
| **RF Importance** | Embedded | Gini importance from Random Forest |
| **Permutation** | Model-agnostic | Importance via feature shuffling |
| **SHAP Values** | Explainability | Game-theoretic feature attribution |

### ğŸ¤– Machine Learning Pipeline

#### Algorithms Implemented

| Model | Hyperparameters Tuned | Strengths |
|-------|----------------------|-----------|
| **Logistic Regression** | C, solver, max_iter | Interpretable, fast, probabilistic |
| **Random Forest** | n_estimators, max_depth, max_features | Robust, handles non-linearity |
| **SVM (RBF)** | C, gamma, kernel | Effective in high dimensions |
| **K-Nearest Neighbors** | n_neighbors, weights, metric | Simple, no training phase |
| **XGBoost** | learning_rate, max_depth, n_estimators, subsample | State-of-the-art performance |

#### Pipeline Components

```python
Pipeline([
    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values
    ('scaler', StandardScaler()),                    # Normalize features
    ('selector', SelectKBest(k=15)),                 # Feature selection
    ('classifier', RandomForestClassifier())         # Classification
])
```

### ğŸ” Model Interpretability

<table>
<tr>
<td width="33%">

#### SHAP Analysis
- ğŸ”µ Summary plots (beeswarm)
- ğŸ”µ Feature importance (bar)
- ğŸ”µ Force plots (individual)
- ğŸ”µ Dependence plots
- ğŸ”µ Interaction values

</td>
<td width="33%">

#### Feature Importance
- ğŸŸ¢ Gini importance (RF)
- ğŸŸ¢ Permutation importance
- ğŸŸ¢ ANOVA F-scores
- ğŸŸ¢ Correlation with target
- ğŸŸ¢ RFE ranking

</td>
<td width="33%">

#### Visualization
- ğŸŸ¡ PCA loadings/biplots
- ğŸŸ¡ Component contributions
- ğŸŸ¡ Correlation networks
- ğŸŸ¡ Feature clustering
- ğŸŸ¡ Importance heatmaps

</td>
</tr>
</table>

### ğŸ“‰ Model Evaluation

#### Metrics Computed

| Metric | Formula | Clinical Relevance |
|--------|---------|-------------------|
| **Accuracy** | (TP+TN)/(TP+TN+FP+FN) | Overall correctness |
| **Precision** | TP/(TP+FP) | Avoid unnecessary biopsies |
| **Recall (Sensitivity)** | TP/(TP+FN) | Catch all malignant cases |
| **Specificity** | TN/(TN+FP) | Correctly identify benign |
| **F1-Score** | 2Ã—(PrecÃ—Rec)/(Prec+Rec) | Balance precision/recall |
| **AUC-ROC** | Area under ROC curve | Discrimination ability |
| **Brier Score** | MSE of probabilities | Calibration quality |

#### Evaluation Techniques

- âœ… Stratified K-Fold Cross-Validation (k=5)
- âœ… Learning Curves (bias-variance tradeoff)
- âœ… Validation Curves (hyperparameter sensitivity)
- âœ… Threshold Optimization (F1/Recall maximization)
- âœ… Calibration Curves (probability reliability)
- âœ… Confusion Matrix Analysis

### ğŸ”® Clustering Analysis

| Algorithm | Parameters | Output |
|-----------|------------|--------|
| **K-Means** | k=2-10, elbow method | Cluster labels, centroids |
| **Hierarchical** | Ward linkage | Dendrogram, cluster labels |
| **Evaluation** | Silhouette, ARI | Cluster quality metrics |

---

## ğŸš€ Quick Start

### Prerequisites

Before running this project, ensure you have:

- ğŸ **Python 3.8+** installed
- ğŸ““ **Jupyter Notebook** or **JupyterLab**
- ğŸ’¾ **8GB+ RAM** (recommended for SHAP/t-SNE)
- ğŸ’» **OS**: Windows, macOS, or Linux

### Installation

#### Option 1: Using pip (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/breast-cancer-analytics.git
cd breast-cancer-analytics

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### Option 2: Using conda

```bash
# Create conda environment
conda create -n cancer-analytics python=3.9 -y
conda activate cancer-analytics

# Install core packages
conda install numpy pandas matplotlib seaborn scikit-learn scipy -y

# Install additional packages
pip install xgboost shap plotly umap-learn missingno networkx joblib
```

#### Option 3: Quick Install (All packages)

```bash
pip install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels \
            xgboost shap plotly umap-learn missingno networkx joypy kaleido joblib
```

### Running the Analysis

#### Step 1: Prepare Data

```bash
# Ensure data.csv is in the project root
ls data.csv  # Should show your dataset
```

#### Step 2: Launch Jupyter

```bash
# Start Jupyter Notebook
jupyter notebook breast_cancer_analytics.ipynb

# Or use JupyterLab
jupyter lab
```

#### Step 3: Execute the Notebook

1. **Open** `breast_cancer_analytics.ipynb`
2. **Run All Cells**: `Kernel` â†’ `Restart & Run All`
3. **Monitor Progress**: Watch for output in each section
4. **Review Results**: Check `figures/`, `reports/`, `artifacts/` folders

### âš™ï¸ Configuration Options

Adjust these flags at the top of the notebook:

```python
# Runtime flags for heavy computations
RUN_SHAP = True          # Set False to skip SHAP analysis (~5 min)
RUN_TSNE = True          # Set False to skip t-SNE embedding (~3 min)
RUN_UMAP = True          # Set False to skip UMAP embedding (~2 min)
WRITE_PLOTLY_IMAGE = False  # Set True if kaleido installed

# Random seed for reproducibility
SEED = 1337

# Paths (adjust if needed)
CSV_PATH_PRIMARY = r"c:\Users\Shank\Desktop\Mandeep\data.csv"
CSV_PATH_FALLBACK = r"./data.csv"
```

### ğŸƒ Quick Test Run

```python
# Minimal test to verify setup
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('data.csv')
print(f"Dataset loaded: {df.shape}")
print(f"Classes: {df['diagnosis'].value_counts().to_dict()}")
```

---

## ğŸ“ Project Structure

```
breast-cancer-analytics/
â”‚
â”œâ”€â”€ ğŸ““ breast_cancer_analytics.ipynb   # ğŸ¯ Main analysis notebook (30 sections)
â”œâ”€â”€ ğŸ“„ data.csv                        # ğŸ“Š Input dataset (569 samples)
â”œâ”€â”€ ğŸ“– README.md                       # ğŸ“š Project documentation (this file)
â”œâ”€â”€ ğŸ“‹ requirements.txt                # ğŸ“¦ Python dependencies
â”œâ”€â”€ ğŸ“œ LICENSE                         # âš–ï¸ MIT License
â”‚
â”œâ”€â”€ ğŸ“‚ data/                           # ğŸ’¾ Data snapshots & metadata
â”‚   â”œâ”€â”€ raw_snapshot.csv               #    â””â”€â”€ Original data sample (10 rows)
â”‚   â”œâ”€â”€ cleaned_snapshot.csv           #    â””â”€â”€ Processed data sample
â”‚   â””â”€â”€ metadata.csv                   #    â””â”€â”€ Feature descriptions & units
â”‚
â”œâ”€â”€ ğŸ“‚ figures/                        # ğŸ¨ Generated visualizations (50+ files)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š Distribution Plots
â”‚   â”‚   â”œâ”€â”€ diagnosis_distribution.png
â”‚   â”‚   â”œâ”€â”€ hist_grid_all_numeric.png
â”‚   â”‚   â”œâ”€â”€ hist_*.png                 # Individual histograms
â”‚   â”‚   â””â”€â”€ dtype_counts.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ˆ Statistical Plots
â”‚   â”‚   â”œâ”€â”€ skewness.png
â”‚   â”‚   â”œâ”€â”€ kurtosis.png
â”‚   â”‚   â”œâ”€â”€ qq_*.png                   # Q-Q plots
â”‚   â”‚   â””â”€â”€ top10_mean_diff.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”— Correlation Plots
â”‚   â”‚   â”œâ”€â”€ corr_heatmap.png
â”‚   â”‚   â”œâ”€â”€ corr_dendrogram.png
â”‚   â”‚   â”œâ”€â”€ corr_network.png
â”‚   â”‚   â””â”€â”€ reg_*.png                  # Regression plots
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‰ Comparison Plots
â”‚   â”‚   â”œâ”€â”€ dist_compare_*.png         # Violin/Box/Strip
â”‚   â”‚   â”œâ”€â”€ pairplot_top8.png
â”‚   â”‚   â””â”€â”€ parallel_coordinates.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ Dimensionality Reduction
â”‚   â”‚   â”œâ”€â”€ pca_scree.png
â”‚   â”‚   â”œâ”€â”€ pca_cumulative.png
â”‚   â”‚   â”œâ”€â”€ pca_2d_scatter.png
â”‚   â”‚   â”œâ”€â”€ pca_3d.html               # Interactive 3D
â”‚   â”‚   â”œâ”€â”€ tsne_diagnosis.png
â”‚   â”‚   â””â”€â”€ umap_diagnosis.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¤– Model Performance
â”‚   â”‚   â”œâ”€â”€ roc_multi.png
â”‚   â”‚   â”œâ”€â”€ pr_multi.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_thresholded.png
â”‚   â”‚   â”œâ”€â”€ calibration_curve_rf.png
â”‚   â”‚   â”œâ”€â”€ learning_curve_rf.png
â”‚   â”‚   â””â”€â”€ validation_curve_svm_C.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ” Feature Importance
â”‚   â”‚   â”œâ”€â”€ selectkbest_top15.png
â”‚   â”‚   â”œâ”€â”€ rf_importances_top15.png
â”‚   â”‚   â”œâ”€â”€ perm_importances_top15.png
â”‚   â”‚   â”œâ”€â”€ shap_summary_beeswarm.png
â”‚   â”‚   â”œâ”€â”€ shap_summary_bar.png
â”‚   â”‚   â””â”€â”€ shap_single_force.png
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”® Clustering
â”‚   â”‚   â”œâ”€â”€ kmeans_elbow_silhouette.png
â”‚   â”‚   â”œâ”€â”€ kmeans_pca_clusters.png
â”‚   â”‚   â”œâ”€â”€ hierarchical_pca_clusters.png
â”‚   â”‚   â””â”€â”€ cluster_vs_diagnosis.png
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“Š Dashboards
â”‚       â”œâ”€â”€ static_dashboard.png
â”‚       â”œâ”€â”€ interactive_dashboard.html
â”‚       â””â”€â”€ final_infographic.png
â”‚
â”œâ”€â”€ ğŸ“‚ reports/                        # ğŸ“‹ Analysis reports (CSV/HTML)
â”‚   â”œâ”€â”€ model_comparison.csv           #    â””â”€â”€ All models' metrics
â”‚   â”œâ”€â”€ feature_importance_comparison.csv
â”‚   â”œâ”€â”€ selectkbest_results.csv
â”‚   â”œâ”€â”€ rf_gridsearch_results.csv
â”‚   â”œâ”€â”€ feature_subset_performance.csv
â”‚   â”œâ”€â”€ grouped_stats_by_diagnosis.csv
â”‚   â”œâ”€â”€ statistical_tests_summary.csv
â”‚   â”œâ”€â”€ misclassified_samples.csv
â”‚   â”œâ”€â”€ head10.html                    #    â””â”€â”€ Styled data preview
â”‚   â”œâ”€â”€ tail10.html
â”‚   â”œâ”€â”€ metadata_preview.html
â”‚   â””â”€â”€ outlier_counts.html
â”‚
â”œâ”€â”€ ğŸ“‚ artifacts/                      # ğŸš€ Deployment artifacts
â”‚   â”œâ”€â”€ model_artifacts.joblib         #    â””â”€â”€ Trained model + scaler + features
â”‚   â”œâ”€â”€ feature_list.json              #    â””â”€â”€ Selected feature names
â”‚   â”œâ”€â”€ model_card.md                  #    â””â”€â”€ Model documentation
â”‚   â””â”€â”€ shap_values_class1.npy         #    â””â”€â”€ SHAP values (optional)
â”‚
â””â”€â”€ ğŸ“‚ notebook/                       # ğŸ““ Additional notebooks (if any)
    â””â”€â”€ (supplementary analyses)
```

### ğŸ“Š Output Summary

| Folder | Files | Description |
|--------|-------|-------------|
| `figures/` | 50+ | PNG/HTML visualizations |
| `reports/` | 12+ | CSV/HTML analysis reports |
| `artifacts/` | 4 | Deployment-ready files |
| `data/` | 3 | Data snapshots & metadata |

---

## ğŸ”¬ Methodology

### Workflow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           END-TO-END ML PIPELINE                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  DATA    â”‚    â”‚  DATA    â”‚    â”‚FEATURE   â”‚    â”‚  MODEL   â”‚    â”‚  MODEL   â”‚
     â”‚  IMPORT  â”‚â”€â”€â”€â–¶â”‚ CLEANING â”‚â”€â”€â”€â–¶â”‚ENGINEER  â”‚â”€â”€â”€â–¶â”‚ TRAINING â”‚â”€â”€â”€â–¶â”‚EVALUATIONâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚               â”‚               â”‚               â”‚               â”‚
          â–¼               â–¼               â–¼               â–¼               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Load CSV â”‚    â”‚ Handle   â”‚    â”‚ Scaling  â”‚    â”‚ CV Split â”‚    â”‚ Metrics  â”‚
     â”‚ Validate â”‚    â”‚ Missing  â”‚    â”‚ PCA      â”‚    â”‚ GridCV   â”‚    â”‚ ROC/PR   â”‚
     â”‚ Snapshot â”‚    â”‚ Outliers â”‚    â”‚ Select   â”‚    â”‚ Fit      â”‚    â”‚ Calibr.  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                           â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
     â”‚  DEPLOY  â”‚â—€â”€â”€â”€â”‚  SHAP    â”‚â—€â”€â”€â”€â”‚ CLUSTER  â”‚â—€â”€â”€â”€â”‚  ERROR   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ARTIFACTS â”‚    â”‚ EXPLAIN  â”‚    â”‚ ANALYSIS â”‚    â”‚ ANALYSIS â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ 30-Section Pipeline

<details>
<summary>ğŸ“– Click to expand complete section breakdown</summary>

| Section | Title | Description | Key Outputs |
|---------|-------|-------------|-------------|
| **1** | Data Import | Load CSV, establish paths | `df_raw`, path configs |
| **2** | Structure Overview | Shape, dtypes, describe | `dtype_counts.png` |
| **3** | Metadata Documentation | Data dictionary | `metadata.csv` |
| **4** | Missing Data Analysis | Quantify missingness | `missing_counts.png` |
| **5** | Duplicate & Zero Analysis | Detect invalid values | `zero_counts.png` |
| **6** | Target Analysis | Class distribution | `diagnosis_distribution.png` |
| **7** | Encode Target | M=1, B=0 mapping | `target` column |
| **8** | Uniqueness & Snapshots | Column cardinality | `raw_snapshot.csv` |
| **9** | Univariate Histograms | Distribution plots | `hist_grid_all_numeric.png` |
| **10** | Normality Analysis | Q-Q, skew, kurtosis | `qq_*.png`, `skewness.png` |
| **11** | Grouped Statistics | Mean/std by class | `grouped_stats_by_diagnosis.csv` |
| **12** | Distribution Comparisons | Violin, box, swarm | `dist_compare_*.png` |
| **13** | Correlation Heatmap | Feature correlations | `corr_heatmap.png` |
| **14** | Top Correlated Pairs | Regression plots | `reg_*.png` |
| **15** | Pairplot & Joint | Multivariate visuals | `pairplot_top8.png` |
| **16** | Outlier Detection | IQR & Z-score | `outlier_counts.html` |
| **17** | Scaling Comparison | Standard/MinMax/Robust | `scaling_compare_*.png` |
| **18** | Multivariate Visuals | Parallel, Andrews | `parallel_coordinates.png` |
| **19** | PCA Analysis | Scree, 2D/3D | `pca_*.png`, `pca_3d.html` |
| **20** | Biplot & Loadings | Component interpretation | `pca_biplot_loadings.png` |
| **21** | SelectKBest | ANOVA F-scores | `selectkbest_results.csv` |
| **22** | Model Importance | RF + Permutation | `rf_importances_top15.png` |
| **23** | SHAP Interpretability | Beeswarm, bar, force | `shap_summary_*.png` |
| **24** | Correlation Network | Graph visualization | `corr_network.png` |
| **25** | RFE Selection | Optimal feature subset | `feature_subset_performance.csv` |
| **26** | Train/Test Split | Stratified 80/20 | `split_class_balance.png` |
| **27** | Multi-Model ROC/PR | 5 algorithms compared | `roc_multi.png`, `pr_multi.png` |
| **28** | Threshold Optimization | F1/Recall trade-off | `threshold_optimization.png` |
| **29** | Hyperparameter Tuning | GridSearchCV | `rf_gridsearch_results.csv` |
| **30** | Final Deployment | Calibration, export | `model_artifacts.joblib` |

</details>

### ğŸ”„ Data Preprocessing Strategy

```python
# Preprocessing Pipeline
def preprocess_data(df):
    """
    Complete preprocessing workflow
    """
    # 1. Handle duplicates
    df = df.drop_duplicates()
    
    # 2. Handle zeros in anatomical features
    for col in ['radius', 'perimeter', 'area']:
        mask = df[col] == 0
        df.loc[mask, col] = df[col].median()
    
    # 3. Encode target
    df['target'] = df['diagnosis'].map({'M': 1, 'B': 0})
    
    # 4. Scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df[feature_cols])
    
    return X_scaled, df['target'], scaler
```

### ğŸ¯ Model Selection Criteria

| Criterion | Weight | Rationale |
|-----------|--------|-----------|
| **AUC-ROC** | 30% | Overall discrimination ability |
| **Recall** | 25% | Critical: catch all malignant cases |
| **Precision** | 20% | Reduce false positives (unnecessary biopsies) |
| **F1-Score** | 15% | Balance precision/recall |
| **Interpretability** | 10% | Clinical trust and adoption |

### ğŸ”§ Hyperparameter Search Space

```python
# Random Forest Grid
rf_params = {
    'n_estimators': [200, 400, 600],
    'max_depth': [None, 5, 10, 15],
    'max_features': ['sqrt', 0.5, 1.0],
    'min_samples_split': [2, 5, 10],
    'class_weight': ['balanced', None]
}

# SVM Grid
svm_params = {
    'C': [0.01, 0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.01, 0.1],
    'kernel': ['rbf', 'poly']
}

# XGBoost Grid
xgb_params = {
    'n_estimators': [200, 400],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [3, 4, 6],
    'subsample': [0.8, 0.9, 1.0]
}
```

---

## ğŸ“ˆ Results

### ğŸ† Model Performance Comparison

<table>
<tr>
<th>Model</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
<th>AUC-ROC</th>
<th>Training Time</th>
</tr>
<tr style="background-color: #d4edda;">
<td><b>ğŸ¥‡ Random Forest</b></td>
<td><b>0.965</b></td>
<td><b>0.953</b></td>
<td><b>0.953</b></td>
<td><b>0.953</b></td>
<td><b>0.995</b></td>
<td>~2.5s</td>
</tr>
<tr>
<td>ğŸ¥ˆ XGBoost</td>
<td>0.956</td>
<td>0.944</td>
<td>0.944</td>
<td>0.944</td>
<td>0.991</td>
<td>~3.0s</td>
</tr>
<tr>
<td>ğŸ¥‰ SVM (RBF)</td>
<td>0.956</td>
<td>0.944</td>
<td>0.944</td>
<td>0.944</td>
<td>0.989</td>
<td>~0.5s</td>
</tr>
<tr>
<td>Logistic Regression</td>
<td>0.947</td>
<td>0.930</td>
<td>0.930</td>
<td>0.930</td>
<td>0.987</td>
<td>~0.1s</td>
</tr>
<tr>
<td>KNN (k=7)</td>
<td>0.939</td>
<td>0.920</td>
<td>0.920</td>
<td>0.920</td>
<td>0.975</td>
<td>~0.05s</td>
</tr>
</table>

### ğŸ“Š Confusion Matrix (Best Model - Random Forest)

```
                    Predicted
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   B      M      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    A    â”‚   B   â”‚   68      3     â”‚  â†’ 95.8% Specificity
    c    â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    t    â”‚   M   â”‚    1     42     â”‚  â†’ 97.7% Sensitivity
    u    â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    a            
    l            â†“      â†“
              98.6%  93.3%
              NPV    PPV
```

### ğŸ¯ Top Discriminative Features

Based on multiple selection methods (SHAP, RF Importance, Permutation, ANOVA):

| Rank | Feature | SHAP | RF Importance | Permutation | ANOVA F |
|------|---------|------|---------------|-------------|---------|
| ğŸ¥‡ 1 | `concave points_worst` | â­â­â­â­â­ | 0.142 | 0.089 | 689.2 |
| ğŸ¥ˆ 2 | `perimeter_worst` | â­â­â­â­â­ | 0.138 | 0.082 | 635.8 |
| ğŸ¥‰ 3 | `area_worst` | â­â­â­â­ | 0.121 | 0.075 | 582.1 |
| 4 | `radius_worst` | â­â­â­â­ | 0.098 | 0.068 | 564.3 |
| 5 | `concavity_mean` | â­â­â­â­ | 0.085 | 0.061 | 521.9 |
| 6 | `concave points_mean` | â­â­â­ | 0.074 | 0.054 | 498.7 |
| 7 | `area_mean` | â­â­â­ | 0.068 | 0.048 | 456.2 |
| 8 | `perimeter_mean` | â­â­â­ | 0.062 | 0.042 | 441.5 |
| 9 | `radius_mean` | â­â­ | 0.055 | 0.038 | 412.8 |
| 10 | `compactness_worst` | â­â­ | 0.048 | 0.032 | 385.4 |

### ğŸ“ˆ Cross-Validation Results

```
5-Fold Stratified Cross-Validation (Random Forest)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Fold 1: AUC = 0.993  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘
Fold 2: AUC = 0.997  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Fold 3: AUC = 0.994  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘
Fold 4: AUC = 0.996  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Fold 5: AUC = 0.995  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Mean:   0.995 Â± 0.002
```

### ğŸ” Key Insights

<table>
<tr>
<td width="50%">

#### âœ… Positive Findings

- ğŸ“ˆ **High separability**: PCA shows clear 2D class separation
- ğŸ¯ **Strong predictors**: "Worst" features most discriminative
- ğŸ”„ **Robust performance**: Low CV variance confirms generalizability
- ğŸ“Š **Well-calibrated**: Probability estimates are reliable
- ğŸ§¬ **Biological sense**: Larger/irregular nuclei â†’ malignancy

</td>
<td width="50%">

#### âš ï¸ Considerations

- ğŸ“Š **Class imbalance**: 63% B vs 37% M (addressed via stratification)
- ğŸ”— **Multicollinearity**: Area/radius/perimeter highly correlated
- ğŸ“‰ **Sensitivity critical**: False negatives more costly clinically
- ğŸ¥ **External validation**: Needed before clinical deployment
- ğŸ“ **Documentation**: Model card included for transparency

</td>
</tr>
</table>

### ğŸ“Š Threshold Optimization Results

| Threshold | Precision | Recall | F1-Score | Clinical Implication |
|-----------|-----------|--------|----------|---------------------|
| 0.30 | 0.89 | 0.98 | 0.93 | High sensitivity, more false alarms |
| 0.40 | 0.92 | 0.96 | 0.94 | Good balance |
| **0.50** | **0.95** | **0.95** | **0.95** | **Optimal F1** |
| 0.60 | 0.97 | 0.91 | 0.94 | High precision, some missed cases |
| 0.70 | 0.98 | 0.85 | 0.91 | Very high precision, more missed |

---

## ğŸ¨ Visualizations

### Gallery

This project generates **50+ publication-quality visualizations**. Here's a categorized overview:

<details>
<summary>ğŸ“Š Distribution & Statistical Plots (Click to expand)</summary>

| Visualization | Description | File |
|--------------|-------------|------|
| Class Distribution | Pie/Donut/Bar of M vs B | `diagnosis_distribution.png` |
| Histogram Grid | All 30 features with KDE | `hist_grid_all_numeric.png` |
| Q-Q Plots | Normality assessment | `qq_*.png` |
| Skewness Chart | Feature skewness ranking | `skewness.png` |
| Kurtosis Chart | Feature kurtosis ranking | `kurtosis.png` |
| Violin Plots | Distribution by class | `dist_compare_*.png` |
| Box Plots | Outlier visualization | `dist_compare_*.png` |
| Strip/Swarm | Individual points | `dist_compare_*.png` |
| Ridge Plots | Joy plots by class | `ridge_plots_top6.png` |

</details>

<details>
<summary>ğŸ”— Correlation & Relationship Plots (Click to expand)</summary>

| Visualization | Description | File |
|--------------|-------------|------|
| Correlation Heatmap | 30Ã—30 feature correlations | `corr_heatmap.png` |
| Dendrogram | Hierarchical clustering | `corr_dendrogram.png` |
| Correlation Network | Graph of strong correlations | `corr_network.png` |
| Regression Plots | Top 20 correlated pairs | `reg_*.png` |
| Joint Plots | Bivariate distributions | `joint_*.png` |
| Hexbin Plots | 2D density | `hex_kde_reg_*.png` |
| Pairplot | 8-feature grid | `pairplot_top8.png` |

</details>

<details>
<summary>ğŸ¯ Dimensionality Reduction (Click to expand)</summary>

| Visualization | Description | File |
|--------------|-------------|------|
| PCA Scree Plot | Variance explained | `pca_scree.png` |
| PCA Cumulative | Cumulative variance | `pca_cumulative.png` |
| PCA 2D Scatter | First 2 components | `pca_2d_scatter.png` |
| PCA 3D Interactive | Plotly 3D | `pca_3d.html` |
| PCA Biplot | Loadings visualization | `pca_biplot_loadings.png` |
| Component Heatmap | Feature contributions | `pca_component_contrib_heatmap.png` |
| t-SNE Plot | Non-linear embedding | `tsne_diagnosis.png` |
| UMAP Plot | Manifold learning | `umap_diagnosis.png` |

</details>

<details>
<summary>ğŸ¤– Model Performance Plots (Click to expand)</summary>

| Visualization | Description | File |
|--------------|-------------|------|
| ROC Curves | Multi-model comparison | `roc_multi.png` |
| PR Curves | Precision-Recall | `pr_multi.png` |
| Confusion Matrix | Thresholded predictions | `confusion_matrix_thresholded.png` |
| Calibration Curve | Probability reliability | `calibration_curve_rf.png` |
| Learning Curve | Bias-variance tradeoff | `learning_curve_rf.png` |
| Validation Curve | Hyperparameter sensitivity | `validation_curve_svm_C.png` |
| Threshold Optimization | Metric vs threshold | `threshold_optimization.png` |
| Prediction Probabilities | Histogram by class | `prediction_probs_by_class.png` |
| Residuals | Error distribution | `residuals_hist.png` |

</details>

<details>
<summary>ğŸ” Feature Importance Plots (Click to expand)</summary>

| Visualization | Description | File |
|--------------|-------------|------|
| SelectKBest | ANOVA F-scores | `selectkbest_top15.png` |
| RF Importance | Gini importance | `rf_importances_top15.png` |
| Permutation Importance | Shuffling-based | `perm_importances_top15.png` |
| Feature Subset AUC | RFE performance | `feature_subset_auc.png` |
| SHAP Beeswarm | Summary plot | `shap_summary_beeswarm.png` |
| SHAP Bar | Mean importance | `shap_summary_bar.png` |
| SHAP Force | Single prediction | `shap_single_force.png` |

</details>

<details>
<summary>ğŸ”® Clustering Plots (Click to expand)</summary>

| Visualization | Description | File |
|--------------|-------------|------|
| Elbow Plot | Optimal k selection | `kmeans_elbow_silhouette.png` |
| Silhouette Scores | Cluster quality | `kmeans_elbow_silhouette.png` |
| KMeans Clusters | PCA projection | `kmeans_pca_clusters.png` |
| Hierarchical Clusters | Agglomerative | `hierarchical_pca_clusters.png` |
| Cluster vs Diagnosis | Confusion matrix | `cluster_vs_diagnosis.png` |

</details>

### ğŸ“Š Interactive Dashboards

| Dashboard | Technology | Features | File |
|-----------|------------|----------|------|
| **3D PCA Explorer** | Plotly | Rotate, zoom, hover tooltips | `figures/pca_3d.html` |
| **Feature Scatter** | Plotly | Interactive scatter with color | `figures/interactive_dashboard.html` |
| **Static Dashboard** | Matplotlib | 12-subplot summary | `figures/static_dashboard.png` |
| **Final Infographic** | Matplotlib | Executive summary | `figures/final_infographic.png` |

### ğŸ–¼ï¸ Sample Visualization Preview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STATIC DASHBOARD LAYOUT                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Diagnosis â”‚   Dtypes   â”‚  Missing   â”‚ Correlationâ”‚  PCA EVR   â”‚
â”‚    Pie     â”‚    Bar     â”‚    Bar     â”‚  Heatmap   â”‚   Line     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PCA 2D    â”‚   BoxPlot  â”‚  Violin    â”‚    ROC     â”‚ Confusion  â”‚
â”‚  Scatter   â”‚   Top Feat â”‚  Top Feat  â”‚  Curves    â”‚  Matrix    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Learning  â”‚                    Calibration                     â”‚
â”‚   Curve    â”‚                      Curve                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– Model Deployment

### Loading the Trained Model

```python
import joblib
import json
import numpy as np

# Load all artifacts
artifacts = joblib.load('artifacts/model_artifacts.joblib')

# Extract components
model = artifacts['model']           # Trained RandomForest
scaler = artifacts['scaler']         # StandardScaler
features = artifacts['selected_features']  # Feature list

# Load feature names separately
with open('artifacts/feature_list.json', 'r') as f:
    feature_names = json.load(f)

print(f"Model loaded: {type(model).__name__}")
print(f"Features: {len(feature_names)}")
```

### ğŸ”® Making Predictions

```python
def predict_diagnosis(sample_dict, threshold=0.5):
    """
    Predict breast cancer diagnosis from feature values.
    
    Parameters:
    -----------
    sample_dict : dict
        Dictionary mapping feature names to values
    threshold : float
        Classification threshold (default=0.5)
    
    Returns:
    --------
    dict : Prediction results with probability and diagnosis
    """
    # Ensure feature order
    sample = np.array([[sample_dict[f] for f in feature_names]])
    
    # Scale features
    sample_scaled = scaler.transform(sample)
    
    # Get probability
    prob_malignant = model.predict_proba(sample_scaled)[0, 1]
    
    # Apply threshold
    diagnosis = 'Malignant' if prob_malignant >= threshold else 'Benign'
    
    # Confidence level
    confidence = abs(prob_malignant - 0.5) * 2  # 0-1 scale
    confidence_label = 'High' if confidence > 0.6 else 'Moderate' if confidence > 0.3 else 'Low'
    
    return {
        'probability': float(prob_malignant),
        'diagnosis': diagnosis,
        'confidence': confidence_label,
        'threshold_used': threshold
    }

# Example usage
sample = {
    'radius_mean': 17.99,
    'texture_mean': 10.38,
    'perimeter_mean': 122.8,
    # ... all 30 features
}
result = predict_diagnosis(sample)
print(f"Diagnosis: {result['diagnosis']} (prob={result['probability']:.3f})")
```

### ğŸŒ API Integration Example

#### Flask REST API

```python
from flask import Flask, request, jsonify
from flask_cors import CORS
import joblib
import numpy as np

app = Flask(__name__)
CORS(app)

# Load model on startup
artifacts = joblib.load('artifacts/model_artifacts.joblib')
model = artifacts['model']
scaler = artifacts['scaler']
features = artifacts['selected_features']

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({'status': 'healthy', 'model': 'RandomForest'})

@app.route('/predict', methods=['POST'])
def predict():
    """
    Prediction endpoint
    
    Request body: {"features": [list of 30 feature values]}
    Response: {"probability": float, "diagnosis": str, "confidence": str}
    """
    try:
        data = request.json
        sample = np.array(data['features']).reshape(1, -1)
        sample_scaled = scaler.transform(sample)
        
        prob = model.predict_proba(sample_scaled)[0, 1]
        diagnosis = 'Malignant' if prob >= 0.5 else 'Benign'
        confidence = 'High' if abs(prob - 0.5) > 0.3 else 'Moderate'
        
        return jsonify({
            'probability': float(prob),
            'diagnosis': diagnosis,
            'confidence': confidence,
            'model_version': '1.0'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/explain', methods=['POST'])
def explain():
    """SHAP explanation endpoint (optional)"""
    # Add SHAP explanations for individual predictions
    pass

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
```

#### FastAPI Alternative

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import numpy as np

app = FastAPI(title="Breast Cancer Prediction API", version="1.0")

# Pydantic models
class PredictionInput(BaseModel):
    features: list[float]
    
class PredictionOutput(BaseModel):
    probability: float
    diagnosis: str
    confidence: str

# Load model
artifacts = joblib.load('artifacts/model_artifacts.joblib')

@app.post("/predict", response_model=PredictionOutput)
async def predict(input_data: PredictionInput):
    if len(input_data.features) != 30:
        raise HTTPException(status_code=400, detail="Expected 30 features")
    
    sample = np.array(input_data.features).reshape(1, -1)
    sample_scaled = artifacts['scaler'].transform(sample)
    prob = artifacts['model'].predict_proba(sample_scaled)[0, 1]
    
    return PredictionOutput(
        probability=prob,
        diagnosis='Malignant' if prob >= 0.5 else 'Benign',
        confidence='High' if abs(prob - 0.5) > 0.3 else 'Moderate'
    )
```

### ğŸ³ Docker Deployment

#### Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy artifacts and app
COPY artifacts/ ./artifacts/
COPY app.py .

# Expose port
EXPOSE 5000

# Run
CMD ["python", "app.py"]
```

#### docker-compose.yml

```yaml
version: '3.8'
services:
  cancer-prediction-api:
    build: .
    ports:
      - "5000:5000"
    environment:
      - MODEL_PATH=/app/artifacts/model_artifacts.joblib
    volumes:
      - ./artifacts:/app/artifacts:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

#### Build & Run

```bash
# Build image
docker build -t cancer-prediction:latest .

# Run container
docker run -p 5000:5000 cancer-prediction:latest

# Test endpoint
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [17.99, 10.38, 122.8, ...]}'
```

---

## ğŸ“Š Statistical Analysis

### Hypothesis Testing Summary

This project employs rigorous statistical methods to validate findings:

| Test | Purpose | When Used | Result |
|------|---------|-----------|--------|
| **Shapiro-Wilk** | Normality test | Before t-test | p > 0.05 â†’ Normal |
| **Independent t-test** | Mean comparison (normal) | Normal features | Significant (p < 0.001) |
| **Mann-Whitney U** | Mean comparison (non-normal) | Skewed features | Significant (p < 0.001) |
| **Cohen's d** | Effect size | All comparisons | Large (d > 0.8) |
| **Power Analysis** | Sample size adequacy | Study design | Power > 0.80 |

### Effect Sizes

```python
# Cohen's d interpretation
d < 0.2  â†’ Negligible effect
d = 0.2  â†’ Small effect
d = 0.5  â†’ Medium effect
d = 0.8+ â†’ Large effect

# Results for top features:
concave_points_worst: d = 2.31 (Very Large)
perimeter_worst:      d = 2.12 (Very Large)
area_worst:           d = 1.98 (Very Large)
radius_worst:         d = 1.89 (Very Large)
```

### Power Analysis

```
Minimum sample size calculation for:
- Effect size: d = 0.8 (large)
- Alpha: 0.05
- Power: 0.80
- Two-tailed test

Required N per group: ~26
Actual N: 212 (M), 357 (B)
Conclusion: âœ… Adequately powered
```

---

## ğŸ§ª Reproducibility

### Ensuring Reproducible Results

This project implements multiple layers of reproducibility:

```python
# 1. Global random seed
SEED = 1337
np.random.seed(SEED)

# 2. Scikit-learn models
RandomForestClassifier(random_state=SEED)
train_test_split(..., random_state=SEED)
StratifiedKFold(..., random_state=SEED)

# 3. Visualization consistency
plt.style.use('seaborn-v0_8-whitegrid')
mpl.rcParams['figure.dpi'] = 300

# 4. Environment documentation
# requirements.txt with pinned versions
```

### Verification Steps

```bash
# 1. Verify Python version
python --version  # Should be 3.8+

# 2. Verify package versions
pip freeze | grep -E "scikit-learn|pandas|numpy"

# 3. Run notebook and compare outputs
jupyter nbconvert --execute breast_cancer_analytics.ipynb

# 4. Check model artifact hashes
md5sum artifacts/model_artifacts.joblib
```

---

## âš ï¸ Clinical Disclaimer

> **ğŸ¥ IMPORTANT MEDICAL DISCLAIMER**
> 
> This analysis and model are intended for **EDUCATIONAL AND RESEARCH PURPOSES ONLY**.

### âŒ This Tool Does NOT:

- Replace professional medical diagnosis
- Constitute medical advice
- Have FDA or regulatory approval
- Have external clinical validation
- Account for patient history/context

### âœ… Proper Clinical Use Requires:

- ğŸ‘¨â€âš•ï¸ **Expert Oversight**: Interpretation by qualified pathologists
- ğŸ”¬ **Additional Testing**: Biopsy, imaging, lab work
- ğŸ“‹ **Full Patient Context**: Medical history, risk factors
- âœ… **External Validation**: Multi-center clinical trials
- ğŸ“œ **Regulatory Approval**: FDA 510(k) or equivalent

### âš–ï¸ Liability Statement

```
THE AUTHORS AND CONTRIBUTORS PROVIDE THIS SOFTWARE "AS IS" WITHOUT 
WARRANTY OF ANY KIND. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY 
CLAIM, DAMAGES OR OTHER LIABILITY ARISING FROM THE USE OF THIS SOFTWARE 
FOR CLINICAL DECISION-MAKING.

Always consult qualified healthcare professionals for medical decisions.
```

### ğŸ“ If You Have Medical Concerns

- **Contact your healthcare provider immediately**
- **Do not rely on this tool for diagnosis**
- **Seek second opinions from specialists**

---

## ğŸ“¦ Dependencies

### Core Libraries (Required)

```
# Data manipulation & analysis
numpy>=1.21.0           # Array operations
pandas>=1.3.0           # DataFrames

# Visualization
matplotlib>=3.4.0       # Base plotting
seaborn>=0.11.0         # Statistical plots

# Machine Learning
scikit-learn>=1.0.0     # ML algorithms & metrics
scipy>=1.7.0            # Statistical functions
statsmodels>=0.13.0     # Advanced statistics

# Utilities
joblib>=1.0.0           # Model persistence
```

### Optional Libraries (Enhanced Features)

```
# Advanced ML
xgboost>=1.5.0          # Gradient boosting (optional model)

# Interpretability
shap>=0.40.0            # SHAP explanations (recommended)

# Interactive Visualization
plotly>=5.0.0           # Interactive plots
kaleido>=0.2.0          # Plotly image export

# Dimensionality Reduction
umap-learn>=0.5.0       # UMAP embedding

# Data Quality
missingno>=0.5.0        # Missing data visualization

# Network Analysis
networkx>=2.6.0         # Correlation networks

# Additional Plots
joypy>=0.2.0            # Ridge/joy plots
```

### ğŸ“‹ requirements.txt

```txt
# Core - Required
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
scipy>=1.7.0
statsmodels>=0.13.0
joblib>=1.0.0

# Optional - Recommended
xgboost>=1.5.0
shap>=0.40.0
plotly>=5.0.0
umap-learn>=0.5.0
missingno>=0.5.0
networkx>=2.6.0
joypy>=0.2.0
kaleido>=0.2.0
```

### Installation Commands

```bash
# Full installation (all features)
pip install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels \
            joblib xgboost shap plotly umap-learn missingno networkx joypy kaleido

# Minimal installation (core only)
pip install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels joblib

# Conda installation
conda install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels joblib -c conda-forge
pip install xgboost shap plotly umap-learn  # Additional from pip
```

---

## ğŸ› ï¸ Execution Notes

### System Requirements

| Requirement | Minimum | Recommended |
|-------------|---------|-------------|
| **RAM** | 4 GB | 8+ GB |
| **CPU** | 2 cores | 4+ cores |
| **Storage** | 500 MB | 1 GB |
| **Python** | 3.8 | 3.9+ |
| **OS** | Win/Mac/Linux | Any |

### â±ï¸ Execution Times

| Component | Time (approx) | Memory |
|-----------|---------------|--------|
| Data Loading & EDA | ~2 min | 200 MB |
| Visualizations | ~5 min | 500 MB |
| Model Training | ~3 min | 400 MB |
| Hyperparameter Tuning | ~5 min | 500 MB |
| SHAP Analysis | ~5 min | 1 GB |
| t-SNE Embedding | ~3 min | 800 MB |
| UMAP Embedding | ~2 min | 600 MB |
| **Total** | **~25 min** | **1-2 GB peak** |

### ğŸ”§ Troubleshooting

<details>
<summary>âŒ SHAP installation fails</summary>

```bash
# Try installing without dependencies
pip install shap --no-deps

# Or skip SHAP entirely
RUN_SHAP = False  # In notebook
```
</details>

<details>
<summary>âŒ Memory errors during t-SNE/UMAP</summary>

```python
# Reduce perplexity for t-SNE
tsne = TSNE(perplexity=15)  # Default is 30

# Or disable these sections
RUN_TSNE = False
RUN_UMAP = False
```
</details>

<details>
<summary>âŒ Plotly images not exporting</summary>

```bash
# Install kaleido
pip install kaleido

# Or disable image export
WRITE_PLOTLY_IMAGE = False
```
</details>

<details>
<summary>âŒ XGBoost not available</summary>

```bash
# Windows
pip install xgboost

# macOS (M1/M2)
conda install -c conda-forge xgboost

# The notebook will gracefully skip if unavailable
```
</details>

<details>
<summary>âŒ Kernel dies during execution</summary>

```python
# Run sections incrementally
# Restart kernel between heavy sections
# Reduce dataset size for testing:
df = df.sample(n=200, random_state=SEED)
```
</details>

---

## ğŸ”® Future Enhancements

### Planned Improvements

| Priority | Enhancement | Status |
|----------|-------------|--------|
| ğŸ”´ High | External dataset validation | Planned |
| ğŸ”´ High | Deep learning models (CNN) | Planned |
| ğŸŸ¡ Medium | Streamlit web application | In Progress |
| ğŸŸ¡ Medium | MLflow experiment tracking | Planned |
| ğŸŸ¢ Low | Automated report generation | Planned |
| ğŸŸ¢ Low | Multi-language support | Future |

### Research Directions

- ğŸ“Š **Multi-modal fusion**: Combine FNA with imaging data
- ğŸ§¬ **Genomic integration**: Add molecular markers
- ğŸ¤– **Transfer learning**: Pre-trained models from larger datasets
- ğŸ“ˆ **Survival analysis**: Time-to-event modeling
- ğŸŒ **Federated learning**: Privacy-preserving training

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get involved:

### Ways to Contribute

1. ğŸ› **Report Bugs**: Open an issue with details
2. ğŸ’¡ **Suggest Features**: Propose enhancements
3. ğŸ“ **Improve Documentation**: Fix typos, add examples
4. ğŸ”§ **Submit Code**: Fork, branch, PR

### Contribution Guidelines

```bash
# 1. Fork the repository
# 2. Create a feature branch
git checkout -b feature/your-feature-name

# 3. Make changes and commit
git commit -m "Add: your feature description"

# 4. Push and create PR
git push origin feature/your-feature-name
```

### Code Standards

- Follow PEP 8 style guide
- Add docstrings to functions
- Include unit tests for new features
- Update README if needed

---

## ğŸ‘©â€ğŸ’» Author

<table>
<tr>
<td width="150">
<img src="https://via.placeholder.com/150" alt="Author" style="border-radius: 50%;">
</td>
<td>

### **Mandeep Kaur**

ğŸ“§ Email: [mandeep@example.com](mailto:mandeep@example.com)  
ğŸ”— LinkedIn: [linkedin.com/in/mandeepkaur](https://linkedin.com/in/mandeepkaur)  
ğŸ™ GitHub: [github.com/mandeepkaur](https://github.com/mandeepkaur)  

**Background**: Data Scientist with expertise in healthcare analytics and machine learning

**Interests**: Medical AI, Explainable ML, Clinical Decision Support Systems

</td>
</tr>
</table>

ğŸ“… **Created**: November 13, 2025  
ğŸ“… **Last Updated**: December 2025  
ğŸ·ï¸ **Version**: 1.0.0

---

## ğŸ“„ License

```
MIT License

Copyright (c) 2025 Mandeep Kaur

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

### Data Sources

- ğŸ›ï¸ **UCI Machine Learning Repository** â€” Original dataset creators
- ğŸ“Š **Kaggle** â€” Dataset hosting and community
- ğŸ”¬ **Dr. William H. Wolberg** â€” University of Wisconsin Hospitals

### Libraries & Tools

| Library | Purpose | Thanks to |
|---------|---------|-----------|
| scikit-learn | ML algorithms | Pedregosa et al. |
| SHAP | Model interpretability | Scott Lundberg |
| Plotly | Interactive visualizations | Plotly Technologies |
| Seaborn | Statistical visualization | Michael Waskom |
| XGBoost | Gradient boosting | Tianqi Chen |
| UMAP | Dimensionality reduction | Leland McInnes |

### Research References

```bibtex
@misc{breast_cancer_wisconsin,
  author = {Wolberg, W.H. and Street, W.N. and Mangasarian, O.L.},
  title = {Breast Cancer Wisconsin (Diagnostic) Data Set},
  year = {1995},
  publisher = {UCI Machine Learning Repository}
}

@article{shap2017,
  title = {A Unified Approach to Interpreting Model Predictions},
  author = {Lundberg, Scott M and Lee, Su-In},
  journal = {NIPS},
  year = {2017}
}
```

### Special Thanks

- ğŸ“ The open-source community for amazing tools
- ğŸ“š Kaggle community for insights and kernels
- ğŸ‘¥ Beta testers and code reviewers

---

<div align="center">

## â­ Star History

If you found this project helpful, please consider giving it a star!

[![Star this repo](https://img.shields.io/github/stars/yourusername/breast-cancer-analytics?style=social)](https://github.com/yourusername/breast-cancer-analytics)

---

### ğŸ“¬ Contact & Support

Have questions? Found a bug? Want to collaborate?

[![Issues](https://img.shields.io/badge/Issues-Report%20Here-red)](https://github.com/yourusername/breast-cancer-analytics/issues)
[![Discussions](https://img.shields.io/badge/Discussions-Join%20Us-blue)](https://github.com/yourusername/breast-cancer-analytics/discussions)

---

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="rainbow line" width="100%">

**Made with â¤ï¸ for the Data Science Community**

*Fighting Cancer with Data Science* ğŸ—ï¸

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="rainbow line" width="100%">

[ğŸ” Back to Top](#-breast-cancer-wisconsin-diagnostic--end-to-end-analytics--modeling)

</div>
